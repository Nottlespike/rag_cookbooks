{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install setuptools==69.5.1 numpy==1.21.3 torch torchvision ftfy faiss-cpu==1.7.4 openai-clip langchain langchain-community langchain-experimental langchain-openai open_clip_torch 'arize-phoenix[evals]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "import glob\n",
    "paths = glob.glob('../images/*.jpeg', recursive=True)\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.trace.langchain import LangChainInstrumentor\n",
    "\n",
    "LangChainInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.open_clip import OpenCLIPEmbeddings\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_docs = []\n",
    "def encode_image(path):\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "for path in paths:\n",
    "    doc = Document(\n",
    "        page_content=encode_image(path),\n",
    "        lookup_str = '',\n",
    "        metadata ={\n",
    "            'source': path\n",
    "        },\n",
    "        lookup_index=0\n",
    "    )\n",
    "    lc_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(lc_docs, embedding=OpenCLIPEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def resize_base64_image(base64_string, size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Resize an image encoded as a Base64 string.\n",
    "\n",
    "    Args:\n",
    "    base64_string (str): Base64 string of the original image.\n",
    "    size (tuple): Desired size of the image as (width, height).\n",
    "\n",
    "    Returns:\n",
    "    str: Base64 string of the resized image.\n",
    "    \"\"\"\n",
    "    # Decode the Base64 string\n",
    "    img_data = base64.b64decode(base64_string)\n",
    "    img = Image.open(io.BytesIO(img_data))\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = img.resize(size, Image.LANCZOS)\n",
    "\n",
    "    # Save the resized image to a bytes buffer\n",
    "    buffered = io.BytesIO()\n",
    "    resized_img.save(buffered, format=img.format)\n",
    "\n",
    "    # Encode the resized image to Base64\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def is_base64(s):\n",
    "    \"\"\"Check if a string is Base64 encoded\"\"\"\n",
    "    try:\n",
    "        return base64.b64encode(base64.b64decode(s)) == s.encode()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def split_image_text_types(docs):\n",
    "    \"\"\"Split numpy array images and texts\"\"\"\n",
    "    images = []\n",
    "    text = []\n",
    "    for doc in docs:\n",
    "        doc = doc.page_content  # Extract Document contents\n",
    "        if is_base64(doc):\n",
    "            # Resize image to avoid OAI server error\n",
    "            images.append(\n",
    "                resize_base64_image(doc, size=(250, 250))\n",
    "            )  # base64 encoded str\n",
    "        else:\n",
    "            text.append(doc)\n",
    "    return {\"images\": images, \"texts\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def prompt_func(data_dict):\n",
    "    # Joining the context texts into a single string\n",
    "    formatted_texts = \"\\n\".join(data_dict[\"context\"][\"texts\"])\n",
    "    messages = []\n",
    "\n",
    "    # Adding image(s) to the messages if present\n",
    "    if data_dict[\"context\"][\"images\"]:\n",
    "        image_message = {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{data_dict['context']['images'][0]}\"\n",
    "            },\n",
    "        }\n",
    "        messages.append(image_message)\n",
    "\n",
    "    # Adding the text message for analysis\n",
    "    text_message = {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": (\n",
    "            \"As an animal lover, your task is to analyze and interpret images of cute animals, \"\n",
    "            \"Please use your extensive knowledge and analytical skills to provide a \"\n",
    "            \"summary that includes:\\n\"\n",
    "            \"- A detailed description of the visual elements in the image.\\n\"\n",
    "            f\"User-provided keywords: {data_dict['question']}\\n\\n\"\n",
    "            \"Text and / or tables:\\n\"\n",
    "            f\"{formatted_texts}\"\n",
    "        ),\n",
    "    }\n",
    "    messages.append(text_message)\n",
    "\n",
    "    return [HumanMessage(content=messages)]\n",
    "\n",
    "\n",
    "foundation = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", max_tokens=1024)\n",
    "\n",
    "# RAG pipeline\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(split_image_text_types),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda(prompt_func)\n",
    "    | foundation\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR [openinference.instrumentation.langchain._tracer] Failed to get attribute.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yujian/Documents/workspace/rag_cookbooks/p310/lib/python3.10/site-packages/openinference/instrumentation/langchain/_tracer.py\", line 274, in wrapper\n",
      "    yield from wrapped(*args, **kwargs)\n",
      "  File \"/Users/yujian/Documents/workspace/rag_cookbooks/p310/lib/python3.10/site-packages/openinference/instrumentation/langchain/_tracer.py\", line 426, in _parse_message_data\n",
      "    assert isinstance(content, str), f\"expected str, found {type(content)}\"\n",
      "AssertionError: expected str, found <class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The image features a German Shepherd, a breed known for its intelligence and versatility. Here‚Äôs a detailed description of the visual elements:\\n\\n### Description of the German Shepherd:\\n- **Coloration**: The dog has a classic coat pattern, predominantly black and tan. The back is mostly black, while the sides and legs exhibit a rich tan color.\\n- **Build**: The German Shepherd has a strong, athletic build with a well-defined musculature. Its body is slightly longer than it is tall, giving it a balanced appearance.\\n- **Head**: The dog has a broad head with a pronounced muzzle. Its ears are erect and pointed, typical of the breed, contributing to its alert expression.\\n- **Eyes**: The eyes are dark and expressive, conveying intelligence and curiosity.\\n- **Tail**: The tail is bushy and hangs down, with a slight curve at the end, which is characteristic of the breed.\\n- **Posture**: The dog stands confidently on a lush green lawn, with its body slightly turned to the side, showcasing its strong legs and overall stature. Its tongue is out, suggesting a playful or relaxed demeanor.\\n\\n### Background:\\n- **Setting**: The background consists of a grassy area, indicating an outdoor environment. There are blurred elements in the background, possibly trees or fencing, which suggest a spacious area for the dog to roam.\\n\\n### Overall Impression:\\nThe German Shepherd appears healthy and well-cared-for, embodying the breed's traits of loyalty and playfulness. The vibrant green grass enhances the visual appeal, creating a lively and cheerful atmosphere.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"german shepard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '../images/dog_1.jpeg'}\n",
      "{'source': '../images/cat_5.jpeg'}\n",
      "{'source': '../images/cat_4.jpeg'}\n",
      "{'source': '../images/cat_3.jpeg'}\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(\"german shepard\", k=3)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR [openinference.instrumentation.langchain._tracer] Failed to get attribute.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yujian/Documents/workspace/rag_cookbooks/p310/lib/python3.10/site-packages/openinference/instrumentation/langchain/_tracer.py\", line 274, in wrapper\n",
      "    yield from wrapped(*args, **kwargs)\n",
      "  File \"/Users/yujian/Documents/workspace/rag_cookbooks/p310/lib/python3.10/site-packages/openinference/instrumentation/langchain/_tracer.py\", line 426, in _parse_message_data\n",
      "    assert isinstance(content, str), f\"expected str, found {type(content)}\"\n",
      "AssertionError: expected str, found <class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The image features a cat lying down on a soft, light-colored surface, likely a carpet. Here‚Äôs a detailed description of the visual elements:\\n\\n- **Subject**: The main focus is a domestic cat, characterized by its striking green eyes and a mix of gray and brown fur with distinct tabby stripes.\\n- **Positioning**: The cat is sprawled out comfortably, with its body elongated and one paw extended forward, suggesting a relaxed and content demeanor.\\n- **Background**: The background is neutral, enhancing the cat's features without distraction. The light color of the surface contrasts nicely with the cat's fur.\\n- **Lighting**: The lighting appears soft and natural, highlighting the cat's fur texture and the vividness of its eyes.\\n- **Expression**: The cat's expression seems calm and curious, with its ears perked up slightly, indicating alertness while still being at ease.\\n\\nOverall, the image captures a serene moment, showcasing the cat's beauty and relaxed nature.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"cat laying down on white background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '../images/cat_4.jpeg'}\n",
      "{'source': '../images/dog_1.jpeg'}\n",
      "{'source': '../images/cat_5.jpeg'}\n",
      "{'source': '../images/cat_3.jpeg'}\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(\"cat laying down on white background\", k=3)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '../images/cat_4.jpeg'}\n",
      "{'source': '../images/dog_1.jpeg'}\n",
      "{'source': '../images/cat_5.jpeg'}\n",
      "{'source': '../images/dog_4.jpeg'}\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(\"cat showing teeth with open mouth\", k=3)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR [openinference.instrumentation.langchain._tracer] Failed to get attribute.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yujian/Documents/workspace/rag_cookbooks/p310/lib/python3.10/site-packages/openinference/instrumentation/langchain/_tracer.py\", line 274, in wrapper\n",
      "    yield from wrapped(*args, **kwargs)\n",
      "  File \"/Users/yujian/Documents/workspace/rag_cookbooks/p310/lib/python3.10/site-packages/openinference/instrumentation/langchain/_tracer.py\", line 426, in _parse_message_data\n",
      "    assert isinstance(content, str), f\"expected str, found {type(content)}\"\n",
      "AssertionError: expected str, found <class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The image features a domestic cat lying on a soft, light-colored carpet. Here are the visual elements observed:\\n\\n- **Cat's Appearance**: The cat has a tabby coat with a mix of gray and brown stripes. Its fur appears soft and well-groomed.\\n- **Eyes**: The cat has striking green eyes that stand out against its fur, giving it an alert and curious expression.\\n- **Mouth**: The cat's mouth is slightly open, revealing its teeth, which adds a playful or inquisitive vibe to its demeanor.\\n- **Pose**: The cat is stretched out comfortably, with one paw extended, suggesting relaxation and contentment.\\n- **Background**: The background is softly blurred, focusing attention on the cat. There is a hint of a blue toy in the background, indicating a playful environment.\\n\\nOverall, the image captures a moment of tranquility and playfulness, showcasing the cat's personality and charm.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"cat showing teeth with open mouth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
